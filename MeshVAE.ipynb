{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e432774b-6485-4086-83cf-02764af43311",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- Обновить на гитхабе этот ноутбук когда доучится"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f3bee0-8646-4579-b5ac-aebf5e7af5b4",
   "metadata": {},
   "source": [
    "# Обучение MeshVAE!\n",
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e7e920-742c-4641-9f6a-ef85c44c3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from torch.utils.checkpoint import checkpoint_sequential\n",
    "from torchvision.transforms import Resize\n",
    "from pathlib import Path\n",
    "\n",
    "from pytorch3d.renderer import look_at_view_transform\n",
    "from pytorch3d.renderer import (\n",
    "FoVPerspectiveCameras, VolumeRenderer,\n",
    "NDCGridRaysampler, EmissionAbsorptionRaymarcher\n",
    ")\n",
    "\n",
    "from modelnet import ModelNetRendersNoLabels\n",
    "\n",
    "from model_collection.MeshVAE import MeshVAE\n",
    "from model_collection.utils import huber_loss, max_VRAM_optim_fit\n",
    "from model_collection.VAE_loss.VaeLoss import VAELoss\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92375b-738a-4b92-a7da-3d36d6537de9",
   "metadata": {},
   "source": [
    "## Set current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8e2f5-5f39-40e2-8399-921ca30598ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'path/to/your/directory'\n",
    "root_dir = Path(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc516114-11a9-468b-a670-5d97c8e207a3",
   "metadata": {},
   "source": [
    "## Определение девайса, датасета и даталоадера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3725d17-087c-408a-91ae-d7a18d6f3242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "Test set has 10 classes\n",
      "Train set has 10 classes\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = True\n",
    "device = 'cuda' if torch.cuda.is_available() and USE_CUDA else 'cpu'\n",
    "print('Using', device)\n",
    "\n",
    "dataset_dir = root_dir / 'dataset'\n",
    "data_sheet = pd.read_csv(dataset_dir / 'modelnet_renders_metadata.csv')\n",
    "data_train = data_sheet[data_sheet['split'] == ' train']\n",
    "data_test = data_sheet[data_sheet['split'] == ' test']\n",
    "\n",
    "image_size = 64\n",
    "transform = transforms.Compose([transforms.Resize(image_size),\n",
    "                                transforms.CenterCrop(image_size),\n",
    "                                transforms.RandomHorizontalFlip(0.5),\n",
    "                                transforms.Normalize(0.5, 0.5)])\n",
    "\n",
    "dataset_train = ModelNetRendersNoLabels(dataset_root_dir=Path(dataset_dir / 'modelNet_renders'),data_sheet=data_train, transform=transform, device=device)\n",
    "dataset_test = ModelNetRendersNoLabels(dataset_root_dir=Path(dataset_dir / 'modelNet_renders'),data_sheet=data_test, transform=transform, device=device)\n",
    "\n",
    "print(f\"Test set has {len(data_test['class'].unique())} classes\\nTrain set has {len(data_train['class'].unique())} classes\")\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset = dataset_train,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      num_workers = 0,\n",
    "                                                      shuffle = True)\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(dataset = dataset_test,\n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      num_workers = 0,\n",
    "                                                      shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9c86c-7e5f-4745-b5e8-49e7c8009127",
   "metadata": {},
   "source": [
    "## Определение модели, оптимизатора и метода learning rate annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba6919f-6c96-421e-9cb8-142a2101e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MeshVAE().to(device)\n",
    "criterion = VAELoss(device=device, clamp=True, clamp_threshold=10000., loss_fn=huber_loss, KLD_coef = 1., reconstruction_coef = 1.)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = None # torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=60, T_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f9bf9-79e3-4692-996d-52743d4c777d",
   "metadata": {},
   "source": [
    "## Обучение!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf89256-b3fc-466a-ae33-4255ea34443f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Epoch 1==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/checkpoint.py:553: UserWarning: torch.utils.checkpoint.checkpoint_sequential: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/student/miniforge3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/student/miniforge3/envs/pytorch3d/lib/python3.9/site-packages/pytorch3d/renderer/implicit/raymarching.py:188: UserWarning: One or more elements of rays_densities are outside of validrange (0.0, 1.0)\n",
      "  warnings.warn(\n",
      "100%|██████████| 998/998 [22:41<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:38<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.80 | Test loss: 4.13\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 2==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:32<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:38<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.94 | Test loss: 3.89\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 3==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:40<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:32<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.76 | Test loss: 3.75\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 4==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:36<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:33<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.66 | Test loss: 3.65\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 5==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:38<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:33<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.58 | Test loss: 3.59\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 6==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:35<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:33<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.50 | Test loss: 3.43\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 7==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:40<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:32<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.36 | Test loss: 3.30\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 8==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:40<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:32<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.08 | Test loss: 2.95\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 9==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:39<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:33<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.87 | Test loss: 2.76\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 10==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:39<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:32<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.74 | Test loss: 2.84\n",
      "Saved weights to models/MeshVAE/10/last.pt\n",
      "==========Epoch 11==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:40<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:33<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.65 | Test loss: 2.74\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 12==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:46<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:33<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.58 | Test loss: 2.61\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 13==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [26:17<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:33<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.51 | Test loss: 2.57\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 14==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:48<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:34<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.46 | Test loss: 2.51\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 15==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:48<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:34<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.41 | Test loss: 2.50\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 16==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:51<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:34<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.39 | Test loss: 2.45\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 17==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:52<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:34<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.36 | Test loss: 2.48\n",
      "Saved weights to models/MeshVAE/10/last.pt\n",
      "==========Epoch 18==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:54<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:34<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.36 | Test loss: 2.48\n",
      "Saved weights to models/MeshVAE/10/last.pt\n",
      "==========Epoch 19==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:47<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:34<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.30 | Test loss: 2.42\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 20==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [23:50<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:34<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.30 | Test loss: 2.44\n",
      "Saved weights to models/MeshVAE/10/last.pt\n",
      "==========Epoch 21==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [24:11<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:41<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.28 | Test loss: 2.40\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 22==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [24:37<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:57<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.27 | Test loss: 2.37\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 23==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [27:28<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:35<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.23 | Test loss: 2.35\n",
      "Saved weights to models/MeshVAE/10/best.pt\n",
      "==========Epoch 24==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [24:02<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:06<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.23 | Test loss: 2.38\n",
      "Saved weights to models/MeshVAE/10/last.pt\n",
      "==========Epoch 25==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [29:43<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:06<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.21 | Test loss: 2.40\n",
      "Saved weights to models/MeshVAE/10/last.pt\n",
      "==========Epoch 26==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [31:49<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:05<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.20 | Test loss: 2.35\n",
      "Saved weights to models/MeshVAE/10/last.pt\n",
      "==========Epoch 27==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [28:30<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:36<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.18 | Test loss: 2.36\n",
      "Saved weights to models/MeshVAE/10/last.pt\n",
      "==========Epoch 28==========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 998/998 [24:06<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:36<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.17 | Test loss: 2.36\n",
      "Saved weights to models/MeshVAE/10/last.pt\n",
      "Restored best weights\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "max_VRAM_optim_fit(train_launch=10,\n",
    "                   model=model, optimizer=optimizer, criterion=criterion,\n",
    "                   train_dl=train_dl, test_dl=test_dl, \n",
    "                   device=device, epochs=epochs,\n",
    "                   scheduler=scheduler,\n",
    "                   weights_save_dir=Path('./models'),\n",
    "                   early_stopping=True, early_stopping_tolerance = 5,\n",
    "                   restore_best_weights=True, save_loss_history=True, overfit_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8262d142-cb52-4b06-8fb1-547b5879a941",
   "metadata": {},
   "source": [
    "## Инференс!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0fd36de6-a78e-4a25-86fa-93f1c8ad164b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeshVAE(\n",
       "  (encoder): Encoder(\n",
       "    (conv_in): Conv3d(40, 64, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3))\n",
       "    (res_down_block1): ResDown(\n",
       "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (act_fnc): ELU(alpha=1.0)\n",
       "    )\n",
       "    (res_down_block2): ResDown(\n",
       "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(256, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (act_fnc): ELU(alpha=1.0)\n",
       "    )\n",
       "    (res_down_block3): ResDown(\n",
       "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(256, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(512, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (act_fnc): ELU(alpha=1.0)\n",
       "    )\n",
       "    (res_down_block4): ResDown(\n",
       "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(512, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(1024, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (act_fnc): ELU(alpha=1.0)\n",
       "    )\n",
       "    (act_fnc): ELU(alpha=1.0)\n",
       "  )\n",
       "  (reparametrize): Reparametrize(\n",
       "    (conv_mu): Conv2d(1024, 512, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (conv_log_var): Conv2d(1024, 512, kernel_size=(4, 4), stride=(1, 1))\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv_t_up): ConvTranspose3d(512, 1024, kernel_size=(4, 4, 4), stride=(1, 1, 1))\n",
       "    (res_up_block1): ResUp(\n",
       "      (conv1): Conv3d(1024, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(512, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(512, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(1024, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (up_nn): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (act_fnc): ELU(alpha=1.0)\n",
       "    )\n",
       "    (res_up_block2): ResUp(\n",
       "      (conv1): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(256, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(256, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (up_nn): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (act_fnc): ELU(alpha=1.0)\n",
       "    )\n",
       "    (res_up_block3): ResUp(\n",
       "      (conv1): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (up_nn): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (act_fnc): ELU(alpha=1.0)\n",
       "    )\n",
       "    (res_up_block4): ResUp(\n",
       "      (conv1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn1): BatchNorm3d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (bn2): BatchNorm3d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (up_nn): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (act_fnc): ELU(alpha=1.0)\n",
       "    )\n",
       "    (conv_out): Conv3d(64, 2, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (act_fnc): ELU(alpha=1.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = MeshVAE().to(device)\n",
    "model.load_state_dict(torch.load(Path('./models') / 'MeshVAE' / '00' / 'best.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3a98b76-3200-45f2-a1bb-a71cbb6b0d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 64, 64]), torch.Size([40, 64, 64]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_model_number = 2500\n",
    "\n",
    "datasets = [dataset_train, dataset_test]\n",
    "dataset = datasets[0]\n",
    "\n",
    "rs = model.render_size\n",
    "resize = Resize((rs, rs))\n",
    "\n",
    "def get_renders():\n",
    "    return torch.stack((dataset[dataset_model_number], dataset[dataset_model_number]), 0)\n",
    "\n",
    "ren_imgs, rend_sils = None, None\n",
    "target_imgs, target_sils = None, None\n",
    "with torch.inference_mode():\n",
    "    # get model\n",
    "    input_renders = get_renders()\n",
    "    target_renders, target_silhouttes = input_renders.to(device).split([1, 1], dim = 1)\n",
    "    target_renders, target_silhouttes = target_renders.squeeze().unsqueeze(2), target_silhouttes.squeeze().unsqueeze(2)\n",
    "    target_imgs, target_sils = target_renders.cpu(), target_silhouttes.cpu()\n",
    "    mu, logvar, output_model = model(target_renders)\n",
    "\n",
    "    num_views, azimuth_range = 40, 180.0\n",
    "    elev = torch.linspace(0, 0, num_views)  # keep constant\n",
    "    azim = torch.linspace(-azimuth_range, azimuth_range, num_views) + 180.0\n",
    "    R, T = look_at_view_transform(dist=2.7, elev=elev, azim=azim)\n",
    "    target_cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
    "    target_cameras = target_cameras.to(device)\n",
    "\n",
    "    rendered_images_silhouettes = model.get_renders(output_model, target_cameras)\n",
    "    rendered_images, rendered_silhouttes = rendered_images_silhouettes.split([1, 1], dim = -1)\n",
    "    ren_imgs, rend_sils = rendered_images.permute(0, 1, 4, 2, 3), rendered_silhouttes.permute(0, 1, 4, 2, 3)\n",
    "\n",
    "    del input_renders\n",
    "    del rendered_images_silhouettes\n",
    "    del rendered_images\n",
    "    del rendered_silhouttes\n",
    "    del target_cameras\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "ren_imgs, rend_sils = ren_imgs.squeeze().detach().cpu()[0], rend_sils.squeeze().detach().cpu()[0]\n",
    "ren_imgs.shape, rend_sils.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c390201d-4d31-480c-821c-929372f7e10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f37de97c7c0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera_num = 25\n",
    "targ_cam = target_imgs[0][camera_num].unsqueeze(0).squeeze()\n",
    "# \n",
    "plt.imshow(torch.hstack((ren_imgs[camera_num] / torch.max(ren_imgs[camera_num]), targ_cam / torch.max(targ_cam))), cmap='gray')\n",
    "# plt.imshow(ren_imgs[camera_num] // torch.max(ren_imgs[camera_num]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f354f8e2-3636-4d05-a183-5e7e1562dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# from skimage import img_as_ubyte\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "imgs = list()\n",
    "save_path = Path('./recreated_models')\n",
    "save_path.mkdir(exist_ok=True)\n",
    "for camera_num, img in enumerate(ren_imgs):\n",
    "    targ_cam = target_imgs[0][camera_num].unsqueeze(0).squeeze()\n",
    "    imgs.append(to_pil_image(torch.hstack((ren_imgs[camera_num] / torch.max(ren_imgs[camera_num]), targ_cam)), mode='L'))\n",
    "    \n",
    "# imageio.mimsave('model_recreated16.gif', imgs)\n",
    "imgs[0].save(save_path / \"out.gif\", save_all=True, append_images=imgs[1:], duration=100, loop=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch3D",
   "language": "python",
   "name": "pytorch3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
